import os
import docx
import pdfplumber
import subprocess

def extract_metadata(filepath):
    """
    Extracts metadata from the file (Author, Creator, etc.)
    Returns: Dict {"author": str, "last_modified_by": str, "creator": str, ...}
    """
    ext = os.path.splitext(filepath)[1].lower()
    metadata = {"author": "Unknown", "creator": "Unknown"}
    
    try:
        if ext == '.docx':
            doc = docx.Document(filepath)
            prop = doc.core_properties
            metadata["author"] = prop.author or "Unknown"
            metadata["last_modified_by"] = prop.last_modified_by or "Unknown"
            metadata["creator"] = "Microsoft Word (Implied)"
            
        elif ext == '.pdf':
            with pdfplumber.open(filepath) as pdf:
                # pdf.metadata is a dict
                raw_meta = pdf.metadata
                if raw_meta:
                    metadata["author"] = raw_meta.get("Author", "Unknown")
                    metadata["creator"] = raw_meta.get("Creator", "Unknown")
                    metadata["producer"] = raw_meta.get("Producer", "Unknown")
                    
        elif ext == '.doc':
            metadata["author"] = "Unknown (Legacy .doc)"
            
    except Exception as e:
        print(f"Error extracting metadata from {filepath}: {e}")
        
    return metadata

def extract_content(filepath):
    """
    Factory function to extract text with page metadata.
    Returns: List[{"text": str, "page": int}]
    """
    ext = os.path.splitext(filepath)[1].lower()
    if ext == '.docx':
        return extract_docx(filepath)
    elif ext == '.pdf':
        return extract_pdf(filepath)
    elif ext == '.doc':
        # legacy doc via antiword doesn't give page numbers easily, treat as single page
        return [{"text": extract_doc(filepath), "page": 1}]
    else:
        raise ValueError(f"不支持的文件格式: {ext} (仅支持 .docx, .doc, .pdf)")

def extract_text(filepath):
    """
    Legacy wrapper for string-only return (if used elsewhere).
    """
    content = extract_content(filepath)
    return "\n".join([item['text'] for item in content])

def extract_docx(filepath):
    """
    Extracts text from a .docx file.
    STRATEGY: 
    1. Try to convert to PDF using LibreOffice (soffice).
    2. If successful, extract from PDF (preserves page numbers).
    3. If failed, fallback to python-docx (Page 1, no pagination).
    """
    # Try converting to PDF first for pagination
    pdf_path = filepath.replace('.docx', '.pdf').replace('.DOCX', '.pdf')
    # Use a temp path to avoid overwriting existing PDFs if any (though usually fine)
    # Actually, let's try to convert in place or temp dir.
    # In Docker, we can write to /tmp.
    
    try:
        # Check if soffice is available
        # On Linux: libreoffice-writer package provides 'soffice' or 'libreoffice'
        # Check with version
        # subprocess.run(['soffice', '--version'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        
        # Convert
        out_dir = os.path.dirname(filepath)
        # Command: soffice --headless --convert-to pdf --outdir <dir> <file>
        cmd = ['soffice', '--headless', '--convert-to', 'pdf', '--outdir', out_dir, filepath]
        
        # On Windows, 'soffice' might not be in PATH. Windows users usually rely on Server for this feature.
        # But we try anyway.
        
        proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=30)
        
        if proc.returncode == 0 and os.path.exists(pdf_path):
            # Success! Extract using PDF extractor logic
            # This ensures consistent segmentation and paging!
            content = extract_pdf(pdf_path)
            
            # Use metadata from Docx (better structured) or PDF?
            # PDF metadata from converted file might be generated by LibreOffice (bad).
            # The 'text_extractor' doesn't return metadata, 'extract_metadata' does.
            # So 'extract_content' calls us, we return content.
            # We should probably delete the generated PDF to save space/confusion?
            # User might want to see it? No, it's intermediate.
            try:
                os.remove(pdf_path)
            except:
                pass
                
            return content
            
    except Exception as e:
        # Fallback (silently or log)
        # print(f"PDF Conversion failed: {e}, falling back to text-only.")
        pass

    # Fallback to python-docx
    doc = docx.Document(filepath)
    full_text = []
    for para in doc.paragraphs:
        if para.text.strip():
            full_text.append(para.text.strip())
    
    # Return as single 'page'
    return [{"text": "\n".join(full_text), "page": 1}]

def extract_doc(filepath):
    # antiword returns string
    # See previous implementation
    try:
        result = subprocess.run(
            ['antiword', filepath], 
            stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE,
            text=True
        )
        if result.returncode != 0:
            if "No such file or directory" in str(result.stderr):
                 raise RuntimeError("系统未安装 antiword 工具。")
            raise RuntimeError(f"antiword 解析失败: {result.stderr.strip()}")
        return result.stdout.strip()
    except FileNotFoundError:
        if os.name == 'nt':
             raise RuntimeError("Windows 本地环境需手动安装 Antiword 或将文件转换为 .docx。\n服务器端(Docker)会自动安装支持。")
        raise RuntimeError("服务器未安装 antiword 工具，请运行 apt-get install antiword")
    except Exception as e:
        raise RuntimeError(f"解析 .doc 文件出错: {str(e)}")

def extract_pdf(filepath):
    """
    Extracts text from a .pdf file using pdfplumber.
    Returns: List[{"text": str, "page": int}]
    """
    content = []
    with pdfplumber.open(filepath) as pdf:
        for i, page in enumerate(pdf.pages):
            page_text = page.extract_text()
            if page_text:
                content.append({
                    "text": page_text, # Keep raw page text (with \n)
                    "page": i + 1
                })
    return content
